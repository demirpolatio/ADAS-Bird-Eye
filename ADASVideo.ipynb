{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200ec127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MAXFRME = 300\n",
    "\n",
    "def extract_frame_from_videos(path1, path2, path3, path4):\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(path1)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    framesF = []\n",
    "    while success and count <MAXFRME:\n",
    "        framesF.append(image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    framesF = np.array(framesF)\n",
    "\n",
    "\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path2)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    framesB = []\n",
    "    while success and count <MAXFRME:\n",
    "        framesB.append(image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    framesB = np.array(framesB)\n",
    "\n",
    "\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path3)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    framesL = []\n",
    "    while success and count <MAXFRME:\n",
    "        framesL.append(image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    framesL = np.array(framesL)\n",
    "\n",
    "\n",
    "    vidcap = cv2.VideoCapture(path4)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    framesR = []\n",
    "    while success and count <MAXFRME:\n",
    "        framesR.append(image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    print(count, \" frames extracted\")\n",
    "    framesR = np.array(framesR)\n",
    "    print(\"data shape =\\t\", framesR.shape)\n",
    "\n",
    "    framesArray = [framesF, framesB, framesL, framesR]\n",
    "    \n",
    "    \n",
    "    return framesArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c2e524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 164, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carImg = cv2.imread('araba/koluman.png')\n",
    "(carH, carW) = carImg.shape[:2]\n",
    "carImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c17a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputframes_to_finalframe(imgF, imgB, imgL, imgR):\n",
    "\n",
    "\n",
    " #-------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Pixel values in original image\n",
    "    red_pointF = [280,210]\n",
    "    green_pointF = [370,210]\n",
    "    black_pointF = [70,350]\n",
    "    blue_pointF = [630,354]\n",
    "\n",
    "    # Create point matrix\n",
    "    point_matrixF = np.float32([red_pointF,green_pointF,black_pointF, blue_pointF])\n",
    "\n",
    "    \n",
    "    # Output image size\n",
    "    widthF, heightF = 600,400\n",
    "\n",
    "    # Desired points value in output images\n",
    "\n",
    "    converted_red_pixel_valueF = [0,0]\n",
    "    converted_green_pixel_valueF = [widthF,0]\n",
    "    converted_black_pixel_valueF = [0,heightF]\n",
    "    converted_blue_pixel_valueF = [widthF,heightF]\n",
    "\n",
    "    # Convert points\n",
    "    converted_pointsF = np.float32([converted_red_pixel_valueF,converted_green_pixel_valueF,\n",
    "                                   converted_black_pixel_valueF,converted_blue_pixel_valueF,\n",
    "                                   ])\n",
    "\n",
    "    # perspective transform\n",
    "    perspective_transformF = cv2.getPerspectiveTransform(point_matrixF,converted_pointsF)\n",
    "    img_OutputF = cv2.warpPerspective(imgF,perspective_transformF,(widthF,heightF))\n",
    "    \n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    " # Pixel values in original image\n",
    "    red_pointB = [0,277]\n",
    "    green_pointB = [284,200]\n",
    "    black_pointB = [640,250]\n",
    "    blue_pointB = [345,197]\n",
    "\n",
    "    # Create point matrix\n",
    "    point_matrixB = np.float32([red_pointB,green_pointB,black_pointB, blue_pointB])\n",
    "\n",
    "    # Output image size\n",
    "    widthB, heightB = 400,600\n",
    "\n",
    "    # Desired points value in output images\n",
    "\n",
    "    converted_red_pixel_valueB = [0,heightB]\n",
    "    converted_green_pixel_valueB = [widthB,heightB]\n",
    "    converted_black_pixel_valueB = [0,0]\n",
    "    converted_blue_pixel_valueB = [widthB,0]\n",
    "\n",
    "\n",
    "    # Convert points\n",
    "    converted_pointsB = np.float32([converted_black_pixel_valueB,converted_blue_pixel_valueB,\n",
    "                                   converted_red_pixel_valueB,converted_green_pixel_valueB\n",
    "                                   ])\n",
    "\n",
    "    # perspective transform\n",
    "    perspective_transformB = cv2.getPerspectiveTransform(point_matrixB,converted_pointsB)\n",
    "    img_OutputB = cv2.warpPerspective(imgB,perspective_transformB,(widthB,heightB))\n",
    "    #img_Output = cv2.rotate(img_Output, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    img_OutputB = cv2.rotate(img_OutputB, cv2.ROTATE_90_CLOCKWISE)\n",
    "      \n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    red_pointL = [80,330]\n",
    "    green_pointL = [160,204]\n",
    "    black_pointL = [500,330]\n",
    "    blue_pointL = [400,210]\n",
    "\n",
    "    # Create point matrix\n",
    "    point_matrixL = np.float32([red_pointL,green_pointL,black_pointL, blue_pointL])\n",
    "\n",
    "\n",
    "    widthL, heightL = 400,500\n",
    "\n",
    "    # Desired points value in output images\n",
    "\n",
    "    converted_red_pixel_valueL = [0,0]\n",
    "    converted_green_pixel_valueL = [widthL,0]\n",
    "    converted_black_pixel_valueL = [0,heightL]\n",
    "    converted_blue_pixel_valueL = [widthL,heightL]\n",
    "\n",
    "\n",
    "    # Convert points\n",
    "    converted_pointsL = np.float32([converted_red_pixel_valueL,converted_green_pixel_valueL,\n",
    "                                   converted_black_pixel_valueL,converted_blue_pixel_valueL])\n",
    "\n",
    "    # perspective transform\n",
    "    perspective_transformL = cv2.getPerspectiveTransform(point_matrixL,converted_pointsL)\n",
    "    img_OutputL = cv2.warpPerspective(imgL,perspective_transformL,(widthL,heightL))\n",
    "    img_OutputL = cv2.rotate(img_OutputL, cv2.ROTATE_180)\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    red_pointR = [120,360]\n",
    "    green_pointR = [240,195]\n",
    "    black_pointR = [640,370]\n",
    "    blue_pointR = [400,195]\n",
    "\n",
    "    # Create point matrix\n",
    "    point_matrixR = np.float32([red_pointR,green_pointR,black_pointR, blue_pointR])\n",
    "\n",
    "    widthR, heightR = 400,500\n",
    "\n",
    "    # Desired points value in output images\n",
    "    converted_red_pixel_valueR = [0,heightR]\n",
    "    converted_green_pixel_valueR = [widthR,heightR]\n",
    "    converted_black_pixel_valueR = [0,0]\n",
    "    converted_blue_pixel_valueR = [widthR,0]\n",
    "\n",
    "\n",
    "    # Convert points\n",
    "    converted_pointsR = np.float32([converted_black_pixel_valueR,converted_blue_pixel_valueR,\n",
    "                                   converted_red_pixel_valueR,converted_green_pixel_valueR\n",
    "                                   ])\n",
    "\n",
    "    # perspective transform\n",
    "    perspective_transformR = cv2.getPerspectiveTransform(point_matrixR,converted_pointsR)\n",
    "    img_OutputR = cv2.warpPerspective(imgR,perspective_transformR,(widthR,heightR))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "    \n",
    "    final_Frame = np.zeros(shape=(1300,870,3),dtype=np.int16)\n",
    "\n",
    "    final_Frame[0:400, 100:700] = img_OutputF[:,:]\n",
    "    final_Frame[900:1300, 100:700] = img_OutputB[:,:]\n",
    "    final_Frame[400:900, 0:400] = img_OutputL[:,:]\n",
    "    final_Frame[400:900, 470:870] = img_OutputR[:,:]\n",
    "\n",
    "\n",
    "    final_Frame[400:400+carH, 320:320+carW] = carImg[:,:]\n",
    "    final_Frame = final_Frame[0:1300, 100:700]\n",
    "\n",
    "\n",
    "    cv2.line(final_Frame,(0,400),(870,400),(0,0,0),10)\n",
    "    cv2.line(final_Frame,(0,900),(870,900),(0,0,0),10)\n",
    "    cv2.line(final_Frame,(384,400),(384,900),(0,0,0),10)\n",
    "    cv2.line(final_Frame,(216,400),(216,900),(0,0,0),10)\n",
    "    \n",
    "    return final_Frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e063b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  frames extracted\n",
      "data shape =\t (300, 480, 640, 3)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    \n",
    "    framelistesi = extract_frame_from_videos(\"front_record.mp4\", \"back_record.mp4\", \"left_record.mp4\", \"right_record.mp4\")\n",
    "    \n",
    "    \n",
    "    finalframes = []\n",
    "    \n",
    "    \n",
    "#     size = 1300, 600\n",
    "#     out = cv2.VideoWriter('./finalframes/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (size[1], size[0]), False)\n",
    "#     for i in range(MAXFRME):\n",
    "#         finalframes.append(inputframes_to_finalframe(framelistesi[0][i], framelistesi[1][i], framelistesi[2][i], framelistesi[3][i]))\n",
    "#         finalframes[i] = finalframes[i][:,:,0]\n",
    "#         out.write(finalframes[i])\n",
    "#     out.release()  \n",
    "    \n",
    "    \n",
    "#     size = 1300, 600\n",
    "#     out = cv2.VideoWriter('./ADASoutput.mp4', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (size[1], size[0]), True)\n",
    "    \n",
    "#     for i in range(MAXFRME):\n",
    "#         finalframes.append(inputframes_to_finalframe(framelistesi[0][i], framelistesi[1][i], framelistesi[2][i], framelistesi[3][i]))\n",
    "#         out.write(finalframes[i].astype('uint8'))\n",
    "#     out.release()  \n",
    "    \n",
    "    \n",
    "    size = 1300, 600\n",
    "    out = cv2.VideoWriter('./ADASoutput.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (size[1], size[0]), True)\n",
    "    \n",
    "    for i in range(MAXFRME):\n",
    "        finalframes.append(inputframes_to_finalframe(framelistesi[0][i], framelistesi[1][i], framelistesi[2][i], framelistesi[3][i]))\n",
    "        out.write(finalframes[i].astype('uint8'))\n",
    "    out.release()  \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "                                      \n",
    "                          \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed7f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
